#!/usr/bin/env python3
"""
æ‰‹ç¶šããƒ‡ãƒ¼ã‚¿ã‚’äº‹å‹™è¦å®šãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«çµ±åˆã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãæ›ãˆãªã—ã§ã®è§£æ±ºæ–¹æ³•
"""
import os
import sys

# ç’°å¢ƒå¤‰æ•°ã¨ãƒ‘ã‚¹è¨­å®š
sys.path.append('/Users/akamatsu/Desktop/ai-agent/src')
os.chdir('/Users/akamatsu/Desktop/ai-agent')

from dotenv import load_dotenv
load_dotenv()

from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import DirectoryLoader, TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

def merge_procedures_to_office():
    """æ‰‹ç¶šããƒ‡ãƒ¼ã‚¿ã‚’äº‹å‹™è¦å®šãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«çµ±åˆ"""
    print("ğŸ”§ æ‰‹ç¶šããƒ‡ãƒ¼ã‚¿ã‚’äº‹å‹™è¦å®šãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«çµ±åˆä¸­...")
    
    # OpenAI EmbeddingsåˆæœŸåŒ–
    embeddings = OpenAIEmbeddings(
        model="text-embedding-3-small"
    )
    
    # æ—¢å­˜ã®äº‹å‹™è¦å®šãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’èª­ã¿è¾¼ã¿
    office_db_path = "src/faiss_index_office"
    if os.path.exists(office_db_path):
        print(f"ğŸ“ æ—¢å­˜ã®äº‹å‹™è¦å®šãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’èª­ã¿è¾¼ã¿ä¸­...")
        office_vectorstore = FAISS.load_local(office_db_path, embeddings, allow_dangerous_deserialization=True)
        print(f"âœ… äº‹å‹™è¦å®šãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹èª­ã¿è¾¼ã¿å®Œäº†")
    else:
        print(f"âŒ äº‹å‹™è¦å®šãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {office_db_path}")
        return False
    
    # æ‰‹ç¶šããƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    procedures_paths = [
        "data/procedures",
        "src/data/procedures"
    ]
    
    all_procedures_docs = []
    
    for path in procedures_paths:
        if os.path.exists(path):
            print(f"ğŸ“ {path} ã‹ã‚‰æ‰‹ç¶šããƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...")
            loader = DirectoryLoader(
                path,
                glob="*.txt",
                loader_cls=TextLoader,
                loader_kwargs={'encoding': 'utf-8'}
            )
            docs = loader.load()
            all_procedures_docs.extend(docs)
            print(f"   -> {len(docs)} ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
    
    if not all_procedures_docs:
        print("âŒ æ‰‹ç¶šããƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return False
    
    print(f"ğŸ“„ ç·æ‰‹ç¶šããƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°: {len(all_procedures_docs)}")
    
    # ãƒ†ã‚­ã‚¹ãƒˆåˆ†å‰²
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200,
        length_function=len,
    )
    
    procedures_texts = text_splitter.split_documents(all_procedures_docs)
    print(f"ğŸ“„ åˆ†å‰²ã—ãŸæ‰‹ç¶šããƒ†ã‚­ã‚¹ãƒˆæ•°: {len(procedures_texts)}")
    
    # æ‰‹ç¶šããƒ‡ãƒ¼ã‚¿ã‚’äº‹å‹™è¦å®šãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è¿½åŠ 
    procedure_vectorstore = FAISS.from_documents(procedures_texts, embeddings)
    
    # æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ãƒãƒ¼ã‚¸
    office_vectorstore.merge_from(procedure_vectorstore)
    print(f"ğŸ”„ æ‰‹ç¶šããƒ‡ãƒ¼ã‚¿ã‚’äº‹å‹™è¦å®šãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«çµ±åˆã—ã¾ã—ãŸ")
    
    # çµ±åˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä¿å­˜
    office_vectorstore.save_local(office_db_path)
    print(f"âœ… çµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {office_db_path}")
    
    # ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚‚ã‚³ãƒ”ãƒ¼
    root_office_path = "faiss_index_office"
    office_vectorstore.save_local(root_office_path)
    print(f"âœ… çµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ã‚³ãƒ”ãƒ¼ã—ã¾ã—ãŸ: {root_office_path}")
    
    return True

if __name__ == "__main__":
    success = merge_procedures_to_office()
    if success:
        print("\nğŸ‰ æ‰‹ç¶šããƒ‡ãƒ¼ã‚¿ã®äº‹å‹™è¦å®šãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¸ã®çµ±åˆãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        print("ğŸ’¡ ã‚µãƒ¼ãƒãƒ¼ã‚’å†èµ·å‹•ã™ã‚‹ã¨ã€adminã‚«ãƒ†ã‚´ãƒªã§æ–°ã—ã„æ‰‹ç¶šãæƒ…å ±ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
        print("\nğŸ“‹ æœŸå¾…ã•ã‚Œã‚‹å‹•ä½œ:")
        print("   ã€ŒçµŒè²»ç²¾ç®—ã®æ–¹æ³•ã‚’æ•™ãˆã¦ã€â†’ æ¯æœˆ20æ—¥ç· åˆ‡ + æ­£ã—ã„URL")
        print("   ã€Œæœ‰çµ¦ç”³è«‹ã®æ–¹æ³•ã‚’æ•™ãˆã¦ã€â†’ æ­£ã—ã„URL + ç”°ä¸­ã•ã‚“ã®é€£çµ¡å…ˆ")
    else:
        print("\nâŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®çµ±åˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
