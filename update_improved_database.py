#!/usr/bin/env python3
"""
æ”¹å–„ã•ã‚ŒãŸæ‰‹ç¶šããƒ‡ãƒ¼ã‚¿ã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’å†çµ±åˆ
"""
import os
import sys

sys.path.append('/Users/akamatsu/Desktop/ai-agent/src')
os.chdir('/Users/akamatsu/Desktop/ai-agent')

from dotenv import load_dotenv
load_dotenv()

from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import DirectoryLoader, TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

def update_office_database():
    """æ”¹å–„ã•ã‚ŒãŸæ‰‹ç¶šããƒ‡ãƒ¼ã‚¿ã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ›´æ–°"""
    print("ğŸ”„ æ”¹å–„ã•ã‚ŒãŸæ‰‹ç¶šããƒ‡ãƒ¼ã‚¿ã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ›´æ–°ä¸­...")
    
    # OpenAI EmbeddingsåˆæœŸåŒ–
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
    
    # äº‹å‹™è¦å®šãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å‰Šé™¤ï¼ˆå†æ§‹ç¯‰ã®ãŸã‚ï¼‰
    import shutil
    office_db_paths = [
        "src/faiss_index_office", 
        "faiss_index_office"
    ]
    
    for path in office_db_paths:
        if os.path.exists(path):
            shutil.rmtree(path)
            print(f"ğŸ—‘ï¸ æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’å‰Šé™¤: {path}")
    
    # 1. äº‹å‹™è¦å®šãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    office_docs = []
    office_docs_path = "src/data/office_docs"
    if os.path.exists(office_docs_path):
        office_loader = DirectoryLoader(
            office_docs_path,
            glob="**/*.md",
            loader_cls=TextLoader,
            loader_kwargs={'encoding': 'utf-8'}
        )
        office_docs = office_loader.load()
        print(f"ğŸ“ äº‹å‹™è¦å®šãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: {len(office_docs)} ãƒ•ã‚¡ã‚¤ãƒ«")
    
    # 2. æ‰‹ç¶šããƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    procedures_docs = []
    procedures_paths = ["data/procedures", "src/data/procedures"]
    
    for path in procedures_paths:
        if os.path.exists(path):
            procedures_loader = DirectoryLoader(
                path,
                glob="*.txt",
                loader_cls=TextLoader,
                loader_kwargs={'encoding': 'utf-8'}
            )
            docs = procedures_loader.load()
            procedures_docs.extend(docs)
            print(f"ğŸ“ {path}: {len(docs)} ãƒ•ã‚¡ã‚¤ãƒ«")
    
    # 3. å…¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆçµ±åˆ
    all_docs = office_docs + procedures_docs
    print(f"ğŸ“„ ç·ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°: {len(all_docs)}")
    
    if not all_docs:
        print("âŒ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return False
    
    # 4. ãƒ†ã‚­ã‚¹ãƒˆåˆ†å‰²
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200
    )
    texts = text_splitter.split_documents(all_docs)
    print(f"ğŸ“„ åˆ†å‰²ãƒ†ã‚­ã‚¹ãƒˆæ•°: {len(texts)}")
    
    # 5. æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä½œæˆ
    vectorstore = FAISS.from_documents(texts, embeddings)
    
    # 6. ä¿å­˜
    vectorstore.save_local("src/faiss_index_office")
    vectorstore.save_local("faiss_index_office")
    print("âœ… çµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä¿å­˜ã—ã¾ã—ãŸ")
    
    return True

if __name__ == "__main__":
    success = update_office_database()
    if success:
        print("\nğŸ‰ æ”¹å–„ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ›´æ–°ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        print("ğŸ’¡ ã‚µãƒ¼ãƒãƒ¼ã‚’å†èµ·å‹•ã—ã¦ãƒ†ã‚¹ãƒˆã—ã¦ãã ã•ã„ã€‚")
        print("\nğŸ“‹ æœŸå¾…ã•ã‚Œã‚‹æ”¹å–„:")
        print("   - ç”°ä¸­ã•ã‚“ã®é€£çµ¡å…ˆæƒ…å ±ãŒç¢ºå®Ÿã«è¡¨ç¤º")
        print("   - ãƒ¡ãƒ¼ãƒ«é€ä¿¡æ©Ÿèƒ½ã®æ¡ˆå†…ãŒå«ã¾ã‚Œã‚‹")
        print("   - ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰å•é¡Œã®è§£æ±ºæ–¹æ³•ãŒæ˜è¨˜")
    else:
        print("\nâŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ›´æ–°ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
